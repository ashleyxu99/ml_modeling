{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia Talk Data - Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook gives an introduction to working with the various data sets in [Wikipedia\n",
    "Talk](https://figshare.com/projects/Wikipedia_Talk/16731) project on Figshare. The release includes:\n",
    "\n",
    "1. a large historical corpus of discussion comments on Wikipedia talk pages\n",
    "2. a sample of over 100k comments with human labels for whether the comment contains a personal attack\n",
    "3. a sample of over 100k comments with human labels for whether the comment has aggressive tone\n",
    "\n",
    "Please refer to our [wiki](https://meta.wikimedia.org/wiki/Research:Detox/Data_Release) for documentation of the schema of each data set and our [research paper](https://arxiv.org/abs/1610.08914) for documentation on the data collection and modeling methodology. \n",
    "\n",
    "In this notebook we show how to build a simple classifier for detecting personal attacks and apply the classifier to a random sample of the comment corpus to see whether discussions on user pages have more personal attacks than discussion on article pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Building a classifier for personal attacks\n",
    "In this section we will train a simple bag-of-words classifier for personal attacks using the [Wikipedia Talk Labels: Personal Attacks]() data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "import unidecode\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download annotated comments and annotations\n",
    "\n",
    "ANNOTATED_COMMENTS_URL = 'https://ndownloader.figshare.com/files/7554634' \n",
    "ANNOTATIONS_URL = 'https://ndownloader.figshare.com/files/7554637' \n",
    "\n",
    "def download_file(url, fname):\n",
    "    urllib.request.urlretrieve(url, fname)\n",
    "\n",
    "# You can edit the code here to download only once, and not download it later                \n",
    "#download_file(ANNOTATED_COMMENTS_URL, 'attack_annotated_comments.tsv')\n",
    "#download_file(ANNOTATIONS_URL, 'attack_annotations.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_csv('attack_annotated_comments.tsv', sep = '\\t', index_col = 0)\n",
    "annotations = pd.read_csv('attack_annotations.tsv',  sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115864"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotations['rev_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels a comment as an attack if the majority of annotators did so\n",
    "labels = annotations.groupby('rev_id')['attack'].mean() > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  comment  year  logged_in  \\\n",
      "rev_id                                                                       \n",
      "37675   `-NEWLINE_TOKENThis is not ``creative``.  Thos...  2002      False   \n",
      "44816   `NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...  2002      False   \n",
      "49851   NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...  2002      False   \n",
      "89320    Next, maybe you could work on being less cond...  2002       True   \n",
      "93890                This page will need disambiguation.   2002       True   \n",
      "102817  NEWLINE_TOKEN-NEWLINE_TOKENNEWLINE_TOKENImport...  2002       True   \n",
      "103624  I removed the following:NEWLINE_TOKENNEWLINE_T...  2002       True   \n",
      "111032  `:If you ever claimed in a Judaic studies prog...  2002       True   \n",
      "120283  NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENMy apol...  2002       True   \n",
      "128532  `Someone wrote:NEWLINE_TOKENMore recognizable,...  2002       True   \n",
      "\n",
      "             ns  sample  split  attack  \n",
      "rev_id                                  \n",
      "37675   article  random  train   False  \n",
      "44816   article  random  train   False  \n",
      "49851   article  random  train   False  \n",
      "89320   article  random    dev   False  \n",
      "93890   article  random  train   False  \n",
      "102817     user  random  train   False  \n",
      "103624  article  random  train   False  \n",
      "111032  article  random    dev   False  \n",
      "120283  article  random    dev   False  \n",
      "128532  article  random  train   False  \n"
     ]
    }
   ],
   "source": [
    "# join labels and comments\n",
    "comments['attack'] = labels\n",
    "print(comments.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the year\n",
    "pYear = comments.query('attack').groupby('year').count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display a bar chartpYear = comments.query('attack').groupby('year').count().reset_index()\n",
    "plt.bar(\"year\", \"attack\", data = pYear, color = \"blue\")\n",
    "plt.xlabel(\"Parameters\")\n",
    "plt.ylabel(\"Attacks\")\n",
    "plt.title(\"Attacks in different years\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   logged_in  comment  year    ns  sample  split  attack\n",
      "0      False     7635  7635  7635    7635   7635    7635\n",
      "1       True     5955  5955  5955    5955   5955    5955\n"
     ]
    }
   ],
   "source": [
    "# Analyze the log_in parameter\n",
    "pLoggedin = comments.query('attack').groupby('logged_in').count().reset_index()\n",
    "print(pLoggedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display a pie chart\n",
    "labels = ['Not Logged In','Logged In' ]\n",
    "colors = ['lightskyblue', 'gold']\n",
    "plt.pie(pLoggedin['attack'], labels= labels, colors=colors, startangle=90, autopct='%.1f%%')\n",
    "plt.title(\"Attacks with different loggined status\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ns  comment   year  logged_in  sample  split  attack\n",
      "0  article     2249   2249       2249    2249   2249    2249\n",
      "1     user    11341  11341      11341   11341  11341   11341\n"
     ]
    }
   ],
   "source": [
    "# Analyze the ns parameter\n",
    "pNS = comments.query('attack').groupby('ns').count().reset_index()\n",
    "print(pNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display a pie chart\n",
    "labels = ['article', 'user']\n",
    "colors = ['lightskyblue', 'gold']\n",
    "plt.pie(pNS['attack'], labels= labels, colors=colors, startangle=90, autopct='%.1f%%')\n",
    "plt.title(\"Attacks with different namespace\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove newline and tab tokens\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower and remove non unicode characters\n",
    "def standardize(text):\n",
    "    return unidecode.unidecode(text.lower())\n",
    "\n",
    "comments['comment'] = comments.comment.apply(standardize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non-alphabetical characters\n",
    "def remove_non_alpha(text):\n",
    "    regex = re.compile('[^a-zA-Z\\s]')\n",
    "    return regex.sub('', text)\n",
    "\n",
    "comments['comment'] = comments.comment.apply(remove_non_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>attack</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>801279</th>\n",
       "      <td>iraq is not good      usa is bad</td>\n",
       "      <td>2003</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2702703</th>\n",
       "      <td>fuck off you little asshole if you want to ...</td>\n",
       "      <td>2004</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4632658</th>\n",
       "      <td>i have a dick its bigger than yours hahaha</td>\n",
       "      <td>2004</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6545332</th>\n",
       "      <td>renault   you sad little bpy for driving a ...</td>\n",
       "      <td>2004</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6545351</th>\n",
       "      <td>renault   you sad little bo for driving a r...</td>\n",
       "      <td>2004</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7977970</th>\n",
       "      <td>nov  utc  because you like to accuse me of r...</td>\n",
       "      <td>2004</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8359431</th>\n",
       "      <td>you are not worth the effort you are arguing...</td>\n",
       "      <td>2004</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8724028</th>\n",
       "      <td>yes complain to your rabbi and then go shoot s...</td>\n",
       "      <td>2004</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8845700</th>\n",
       "      <td>i am using the sandbox ass wipe</td>\n",
       "      <td>2004</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8845736</th>\n",
       "      <td>god damn   god damn it fuckers i am using t...</td>\n",
       "      <td>2004</td>\n",
       "      <td>False</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>dev</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   comment  year  logged_in  \\\n",
       "rev_id                                                                        \n",
       "801279                 iraq is not good      usa is bad     2003      False   \n",
       "2702703     fuck off you little asshole if you want to ...  2004      False   \n",
       "4632658         i have a dick its bigger than yours hahaha  2004      False   \n",
       "6545332     renault   you sad little bpy for driving a ...  2004       True   \n",
       "6545351     renault   you sad little bo for driving a r...  2004       True   \n",
       "7977970    nov  utc  because you like to accuse me of r...  2004       True   \n",
       "8359431    you are not worth the effort you are arguing...  2004       True   \n",
       "8724028  yes complain to your rabbi and then go shoot s...  2004       True   \n",
       "8845700                    i am using the sandbox ass wipe  2004      False   \n",
       "8845736     god damn   god damn it fuckers i am using t...  2004      False   \n",
       "\n",
       "              ns   sample  split  attack  \n",
       "rev_id                                    \n",
       "801279   article   random  train    True  \n",
       "2702703     user   random  train    True  \n",
       "4632658  article  blocked  train    True  \n",
       "6545332     user  blocked  train    True  \n",
       "6545351     user  blocked   test    True  \n",
       "7977970  article   random  train    True  \n",
       "8359431     user  blocked  train    True  \n",
       "8724028     user  blocked   test    True  \n",
       "8845700     user  blocked  train    True  \n",
       "8845736     user  blocked    dev    True  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.query('attack').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rev_id\n",
       "801279                   iraq is not good      usa is bad   \n",
       "2702703       fuck off you little asshole if you want to ...\n",
       "4632658           i have a dick its bigger than yours hahaha\n",
       "6545332       renault   you sad little bpy for driving a ...\n",
       "6545351       renault   you sad little bo for driving a r...\n",
       "7977970      nov  utc  because you like to accuse me of r...\n",
       "8359431      you are not worth the effort you are arguing...\n",
       "8724028    yes complain to your rabbi and then go shoot s...\n",
       "8845700                      i am using the sandbox ass wipe\n",
       "8845736       god damn   god damn it fuckers i am using t...\n",
       "Name: comment, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.query('attack')['comment'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample DecsionTree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.95      0.95     20422\n",
      "        True       0.65      0.62      0.64      2756\n",
      "\n",
      "    accuracy                           0.92     23178\n",
      "   macro avg       0.80      0.79      0.79     23178\n",
      "weighted avg       0.91      0.92      0.91     23178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit a simple text classifier\n",
    "\n",
    "train_comments = comments.query(\"split=='train'\")\n",
    "test_comments = comments.query(\"split=='test'\")\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000, ngram_range = (1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf', DecisionTreeClassifier(random_state = 123)),\n",
    "])\n",
    "clf = clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "\n",
    "met = metrics.classification_report(test_comments['attack'], clf.predict(test_comments['comment']))\n",
    "print(met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7996659690138055, 0.7893503320858763, 0.7943751638587662, None)\n"
     ]
    }
   ],
   "source": [
    "metirc2 = precision_recall_fscore_support(test_comments['attack'], clf.predict(test_comments['comment']), average='macro')\n",
    "print(metirc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly classify nice comment\n",
    "clf.predict(['Thanks for you contribution, you did a great job!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly classify nasty comment\n",
    "clf.predict(['People as stupid as you should not edit Wikipedia!'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over-sampling Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "train_comments = comments.query(\"split=='train'\")\n",
    "test_comments = comments.query(\"split=='test'\")\n",
    "\n",
    "X_train=train_comments['comment'].head(14000)\n",
    "y_train=train_comments['attack'].head(14000)\n",
    "X_test=test_comments['comment']\n",
    "y_test=test_comments['attack']\n",
    "\n",
    "vectorizer1 = CountVectorizer(max_features = 10000, ngram_range = (1,2))\n",
    "vectorizer1.fit(X_train.values.ravel())\n",
    "X_train=vectorizer.transform(X_train.values.ravel())\n",
    "X_test=vectorizer.transform(X_test.values.ravel())\n",
    "X_train=X_train.toarray()\n",
    "X_test=X_test.toarray()\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=2)\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7906204159116403"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state = 123).fit(X_res, y_res)\n",
    "\n",
    "# Return the mean accuracy on the given test data and labels.\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7881611873328156"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "                                 max_depth=1, random_state=0).fit(X_res, y_res)\n",
    "# Return the mean accuracy on the given test data and labels.\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8478729830011218"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X_res, y_res)\n",
    "# Return the mean accuracy on the given test data and labels.\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultinomialNB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9163430839589266"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB().fit(X_res, y_res)\n",
    "# Return the mean accuracy on the given test data and labels.\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMV Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel='linear', gamma='auto').fit(X_res, y_res)\n",
    "# Return the mean accuracy on the given test data and labels.\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "union = FeatureUnion([(\"pca\", PCA(n_components=1)),\n",
    "                       (\"svd\", TruncatedSVD(n_components=2)), \n",
    "                      ('vect', CountVectorizer(max_features = 10000, ngram_range = (1,2))),\n",
    "                      ('tfidf', TfidfTransformer(norm = 'l2'))])\n",
    "\n",
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"For data grouped by feature, select subset of data at a provided key.\n",
    "\n",
    "    The data is expected to be stored in a 2D data structure, where the first\n",
    "    index is over features and the second is over samples.  i.e.\n",
    "\n",
    "    >> len(data[key]) == n_samples\n",
    "\n",
    "    Please note that this is the opposite convention to scikit-learn feature\n",
    "    matrixes (where the first index corresponds to sample).\n",
    "\n",
    "    ItemSelector only requires that the collection implement getitem\n",
    "    (data[key]).  Examples include: a dict of lists, 2D numpy array, Pandas\n",
    "    DataFrame, numpy record array, etc.\n",
    "\n",
    "    >> data = {'a': [1, 5, 2, 5, 2, 8],\n",
    "               'b': [9, 4, 1, 4, 1, 3]}\n",
    "    >> ds = ItemSelector(key='a')\n",
    "    >> data['a'] == ds.transform(data)\n",
    "\n",
    "    ItemSelector is not designed to handle data grouped by sample.  (e.g. a\n",
    "    list of dicts).  If your data is structured this way, consider a\n",
    "    transformer along the lines of `sklearn.feature_extraction.DictVectorizer`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    key : hashable, required\n",
    "        The key corresponding to the desired value in a mappable.\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextStats(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, posts):\n",
    "        return [{'length': len(text),\n",
    "                 'num_sentences': text.count('.')}\n",
    "                for text in posts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zd/_qrx7mbs5b99x8gl0m_83tpr0000gn/T/ipykernel_1045/519853465.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'svc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m ])\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_comments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_comments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attack'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0mmet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_comments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attack'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_comments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \"\"\"\n\u001b[1;32m    389\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pipeline\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;31m# Fit or load from cache the current transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    349\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0msum\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m \u001b[0mdimension\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mover\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \"\"\"\n\u001b[0;32m-> 1172\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parallel_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m             \u001b[0;31m# All transformers are None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_parallel_func\u001b[0;34m(self, X, y, fit_params, func)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mtransformers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m         return Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[1;32m   1195\u001b[0m             delayed(func)(\n\u001b[1;32m   1196\u001b[0m                 \u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2075\u001b[0m         \"\"\"\n\u001b[1;32m   2076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2077\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2078\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2079\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1330\u001b[0;31m         \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1201\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1202\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \"\"\"\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "train_comments = comments.query(\"split=='train'\")\n",
    "test_comments = comments.query(\"split=='test'\")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "\n",
    "    # Use FeatureUnion to combine the features from subject and body\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "\n",
    "            # Pipeline for pulling features from the year\n",
    "            ('year', Pipeline([\n",
    "                ('selector', ItemSelector(key='year')),\n",
    "                ('tfidf', TfidfVectorizer(min_df=50)),\n",
    "            ])),\n",
    "\n",
    "            # Pipeline for standard bag-of-words model for body\n",
    "            ('comment', Pipeline([\n",
    "                ('selector', ItemSelector(key='comment')),\n",
    "                ('tfidf', TfidfVectorizer()),\n",
    "                ('best', TruncatedSVD(n_components=50)),\n",
    "            ])),\n",
    "\n",
    "            # Pipeline for pulling ad hoc features from post's body\n",
    "            ('namespace', Pipeline([\n",
    "                ('selector', ItemSelector(key='ns')),\n",
    "                ('stats', TextStats()),  # returns a list of dicts\n",
    "                ('vect', DictVectorizer()),  # list of dicts -> feature matrix\n",
    "            ])),\n",
    "\n",
    "        ],\n",
    "\n",
    "        # weight components in FeatureUnion\n",
    "        transformer_weights={\n",
    "            'year': 0.8,\n",
    "            'comment': 0.5,\n",
    "            'namespace': 1.0,\n",
    "        },\n",
    "    )),\n",
    "\n",
    "    # Use a SVC classifier on the combined features\n",
    "    ('svc', SVC(kernel='linear')),\n",
    "])\n",
    "pipeline = pipeline.fit(train_comments, train_comments['attack'])\n",
    "met = metrics.classification_report(test_comments['attack'], pipeline.predict(test_comments))\n",
    "print(met)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.99      0.97     20422\n",
      "        True       0.92      0.55      0.69      2756\n",
      "\n",
      "    accuracy                           0.94     23178\n",
      "   macro avg       0.93      0.77      0.83     23178\n",
      "weighted avg       0.94      0.94      0.93     23178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit a simple text classifier\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "train_comments = comments.query(\"split=='train'\")\n",
    "test_comments = comments.query(\"split=='test'\")\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000, ngram_range = (1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf', LogisticRegression(random_state=0)),\n",
    "])\n",
    "clf = clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "met = metrics.classification_report(test_comments['attack'], clf.predict(test_comments['comment']))\n",
    "print(met)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9306871762038317, 0.772118353538594, 0.8280202850751003, None)\n"
     ]
    }
   ],
   "source": [
    "metirc2 = precision_recall_fscore_support(test_comments['attack'], clf.predict(test_comments['comment']), average='macro')\n",
    "print(metirc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultinomialNB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.99      0.96     20422\n",
      "        True       0.88      0.51      0.64      2756\n",
      "\n",
      "    accuracy                           0.93     23178\n",
      "   macro avg       0.91      0.75      0.80     23178\n",
      "weighted avg       0.93      0.93      0.93     23178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "train_comments = comments.query(\"split=='train'\")\n",
    "test_comments = comments.query(\"split=='test'\")\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000, ngram_range = (1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "clf = clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "met = metrics.classification_report(test_comments['attack'], clf.predict(test_comments['comment']))\n",
    "print(met)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9081907751028948, 0.7498102625316987, 0.8039775054686669, None)\n"
     ]
    }
   ],
   "source": [
    "metirc3 = precision_recall_fscore_support(test_comments['attack'], clf.predict(test_comments['comment']), average='macro')\n",
    "print(metirc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMV Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.99      0.97     20422\n",
      "        True       0.90      0.60      0.72      2756\n",
      "\n",
      "    accuracy                           0.94     23178\n",
      "   macro avg       0.92      0.80      0.84     23178\n",
      "weighted avg       0.94      0.94      0.94     23178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "train_comments = comments.query(\"split=='train'\")\n",
    "test_comments = comments.query(\"split=='test'\")\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000, ngram_range = (1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf', SVC(kernel='linear', gamma='auto')),\n",
    "])\n",
    "clf = clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "met = metrics.classification_report(test_comments['attack'], clf.predict(test_comments['comment']))\n",
    "print(met)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters Tuning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Logistice Regress model gives the best result according to the confusion martics, I will continue to optimize the model by using hyperparameters tuning, trying different parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also use k-fold cross-validation and set k = 2. Therefore, we attempt to maximize the use of the available data for training and then testing a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "pipe = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000)),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf', LogisticRegression(random_state=0)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'vect', 'tfidf', 'clf', 'vect__analyzer', 'vect__binary', 'vect__decode_error', 'vect__dtype', 'vect__encoding', 'vect__input', 'vect__lowercase', 'vect__max_df', 'vect__max_features', 'vect__min_df', 'vect__ngram_range', 'vect__preprocessor', 'vect__stop_words', 'vect__strip_accents', 'vect__token_pattern', 'vect__tokenizer', 'vect__vocabulary', 'tfidf__norm', 'tfidf__smooth_idf', 'tfidf__sublinear_tf', 'tfidf__use_idf', 'clf__C', 'clf__class_weight', 'clf__dual', 'clf__fit_intercept', 'clf__intercept_scaling', 'clf__l1_ratio', 'clf__max_iter', 'clf__multi_class', 'clf__n_jobs', 'clf__penalty', 'clf__random_state', 'clf__solver', 'clf__tol', 'clf__verbose', 'clf__warm_start'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 24 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "24 fits failed out of a total of 48.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "24 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.931709   0.93163709        nan        nan\n",
      " 0.93685815 0.93651296        nan        nan 0.94091419 0.94010874\n",
      "        nan        nan 0.94029572 0.93947588        nan        nan\n",
      " 0.93389523 0.93127751        nan        nan 0.92952277 0.92707764]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([ 10.13237143,  40.13182962,  11.27746248,  42.53912842,\n",
      "        14.78471053,  46.31410253,  15.90874791,  59.37552547,\n",
      "        13.2542491 ,  64.80201411,  17.10616601,  64.42846835,\n",
      "        17.32607496,  32.8082875 ,  16.92709577,  86.93640447,\n",
      "        27.47506702, 165.06145144,  56.19363844,  87.60426247,\n",
      "        27.964908  ,  75.60427296,  24.20180845,  25.07821608]), 'std_fit_time': array([4.72890377e-01, 5.90860844e-03, 4.75875378e-01, 1.73262346e+00,\n",
      "       1.33623946e+00, 8.98770452e-01, 1.14425111e+00, 4.92912531e-01,\n",
      "       1.87409019e+00, 5.03989196e+00, 3.31884027e-01, 5.77374697e-02,\n",
      "       1.72934020e+00, 5.21664035e+00, 9.39029098e-01, 3.45527925e+01,\n",
      "       7.73879993e+00, 7.69204140e+00, 8.72306764e+00, 1.33573364e+01,\n",
      "       1.17731202e+00, 4.07794797e+00, 2.56445456e+00, 3.17653894e-01]), 'mean_score_time': array([ 0.        ,  0.        ,  7.14484966, 11.17938173,  0.        ,\n",
      "        0.        ,  6.65084088, 16.19774902,  0.        ,  0.        ,\n",
      "       10.05668092, 14.07220709,  0.        ,  0.        ,  7.81634009,\n",
      "       29.03758812,  0.        ,  0.        , 10.23154008, 29.00022054,\n",
      "        0.        ,  0.        , 10.01016104,  5.03088689]), 'std_score_time': array([0.        , 0.        , 0.38462842, 1.0981096 , 0.        ,\n",
      "       0.        , 0.23742402, 0.77978981, 0.        , 0.        ,\n",
      "       0.26550007, 1.54246891, 0.        , 0.        , 0.68177402,\n",
      "       6.61490798, 0.        , 0.        , 0.04644096, 6.29612756,\n",
      "       0.        , 0.        , 5.88194025, 0.44510412]), 'param_clf__C': masked_array(data=[0.5, 0.5, 0.5, 0.5, 1, 1, 1, 1, 5, 5, 5, 5, 10, 10, 10,\n",
      "                   10, 50, 50, 50, 50, 100, 100, 100, 100],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_clf__penalty': masked_array(data=['l1', 'l1', 'l2', 'l2', 'l1', 'l1', 'l2', 'l2', 'l1',\n",
      "                   'l1', 'l2', 'l2', 'l1', 'l1', 'l2', 'l2', 'l1', 'l1',\n",
      "                   'l2', 'l2', 'l1', 'l1', 'l2', 'l2'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_vect__ngram_range': masked_array(data=[(1, 2), (1, 3), (1, 2), (1, 3), (1, 2), (1, 3), (1, 2),\n",
      "                   (1, 3), (1, 2), (1, 3), (1, 2), (1, 3), (1, 2), (1, 3),\n",
      "                   (1, 2), (1, 3), (1, 2), (1, 3), (1, 2), (1, 3), (1, 2),\n",
      "                   (1, 3), (1, 2), (1, 3)],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'clf__C': 0.5, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 2)}, {'clf__C': 0.5, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 3)}, {'clf__C': 0.5, 'clf__penalty': 'l2', 'vect__ngram_range': (1, 2)}, {'clf__C': 0.5, 'clf__penalty': 'l2', 'vect__ngram_range': (1, 3)}, {'clf__C': 1, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 2)}, {'clf__C': 1, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 3)}, {'clf__C': 1, 'clf__penalty': 'l2', 'vect__ngram_range': (1, 2)}, {'clf__C': 1, 'clf__penalty': 'l2', 'vect__ngram_range': (1, 3)}, {'clf__C': 5, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 2)}, {'clf__C': 5, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 3)}, {'clf__C': 5, 'clf__penalty': 'l2', 'vect__ngram_range': (1, 2)}, {'clf__C': 5, 'clf__penalty': 'l2', 'vect__ngram_range': (1, 3)}, {'clf__C': 10, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 2)}, {'clf__C': 10, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 3)}, {'clf__C': 10, 'clf__penalty': 'l2', 'vect__ngram_range': (1, 2)}, {'clf__C': 10, 'clf__penalty': 'l2', 'vect__ngram_range': (1, 3)}, {'clf__C': 50, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 2)}, {'clf__C': 50, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 3)}, {'clf__C': 50, 'clf__penalty': 'l2', 'vect__ngram_range': (1, 2)}, {'clf__C': 50, 'clf__penalty': 'l2', 'vect__ngram_range': (1, 3)}, {'clf__C': 100, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 2)}, {'clf__C': 100, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 3)}, {'clf__C': 100, 'clf__penalty': 'l2', 'vect__ngram_range': (1, 2)}, {'clf__C': 100, 'clf__penalty': 'l2', 'vect__ngram_range': (1, 3)}], 'split0_test_score': array([       nan,        nan, 0.93191036, 0.931709  ,        nan,\n",
      "              nan, 0.93708828, 0.93697322,        nan,        nan,\n",
      "       0.94062653, 0.93956218,        nan,        nan, 0.93927452,\n",
      "       0.93806633,        nan,        nan, 0.93119121, 0.92822829,\n",
      "              nan,        nan, 0.92702011, 0.92305037]), 'split1_test_score': array([       nan,        nan, 0.93150764, 0.93156517,        nan,\n",
      "              nan, 0.93662802, 0.9360527 ,        nan,        nan,\n",
      "       0.94120185, 0.94065529,        nan,        nan, 0.94131692,\n",
      "       0.94088542,        nan,        nan, 0.93659926, 0.93432673,\n",
      "              nan,        nan, 0.93202543, 0.93110491]), 'mean_test_score': array([       nan,        nan, 0.931709  , 0.93163709,        nan,\n",
      "              nan, 0.93685815, 0.93651296,        nan,        nan,\n",
      "       0.94091419, 0.94010874,        nan,        nan, 0.94029572,\n",
      "       0.93947588,        nan,        nan, 0.93389523, 0.93127751,\n",
      "              nan,        nan, 0.92952277, 0.92707764]), 'std_test_score': array([           nan,            nan, 2.01363519e-04, 7.19155424e-05,\n",
      "                  nan,            nan, 2.30129736e-04, 4.60259471e-04,\n",
      "                  nan,            nan, 2.87662170e-04, 5.46558122e-04,\n",
      "                  nan,            nan, 1.02120070e-03, 1.40954463e-03,\n",
      "                  nan,            nan, 2.70402439e-03, 3.04921900e-03,\n",
      "                  nan,            nan, 2.50266088e-03, 4.02727037e-03]), 'rank_test_score': array([24, 20,  8,  9, 19, 16,  5,  6, 15, 23,  1,  3, 13, 14,  2,  4, 17,\n",
      "       18,  7, 10, 21, 22, 11, 12], dtype=int32)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# param_grid = dict(estimator__clf__penalty=['l1', 'l2'], estimator__clf__C=[0.5, 1, 5, 10, 50, 100])\n",
    "param_grid = {'clf__penalty':['l1', 'l2'], \n",
    "              'clf__C':[0.5, 1, 5, 10, 50, 100],\n",
    "              'vect__ngram_range':[(1, 2), (1, 3)]\n",
    "             }\n",
    "\n",
    "clf = GridSearchCV(pipe, param_grid, verbose=10, n_jobs=-1, cv=2, return_train_score=False, scoring=\"accuracy\")\n",
    "\n",
    "clf = clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "print(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cv', 'error_score', 'estimator__memory', 'estimator__steps', 'estimator__verbose', 'estimator__vect', 'estimator__tfidf', 'estimator__clf', 'estimator__vect__analyzer', 'estimator__vect__binary', 'estimator__vect__decode_error', 'estimator__vect__dtype', 'estimator__vect__encoding', 'estimator__vect__input', 'estimator__vect__lowercase', 'estimator__vect__max_df', 'estimator__vect__max_features', 'estimator__vect__min_df', 'estimator__vect__ngram_range', 'estimator__vect__preprocessor', 'estimator__vect__stop_words', 'estimator__vect__strip_accents', 'estimator__vect__token_pattern', 'estimator__vect__tokenizer', 'estimator__vect__vocabulary', 'estimator__tfidf__norm', 'estimator__tfidf__smooth_idf', 'estimator__tfidf__sublinear_tf', 'estimator__tfidf__use_idf', 'estimator__clf__C', 'estimator__clf__class_weight', 'estimator__clf__dual', 'estimator__clf__fit_intercept', 'estimator__clf__intercept_scaling', 'estimator__clf__l1_ratio', 'estimator__clf__max_iter', 'estimator__clf__multi_class', 'estimator__clf__n_jobs', 'estimator__clf__penalty', 'estimator__clf__random_state', 'estimator__clf__solver', 'estimator__clf__tol', 'estimator__clf__verbose', 'estimator__clf__warm_start', 'estimator', 'n_jobs', 'param_grid', 'pre_dispatch', 'refit', 'return_train_score', 'scoring', 'verbose'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_clf__C  \\\n",
      "0       10.132371      0.472890         0.000000        0.000000          0.5   \n",
      "1       40.131830      0.005909         0.000000        0.000000          0.5   \n",
      "2       11.277462      0.475875         7.144850        0.384628          0.5   \n",
      "3       42.539128      1.732623        11.179382        1.098110          0.5   \n",
      "4       14.784711      1.336239         0.000000        0.000000            1   \n",
      "5       46.314103      0.898770         0.000000        0.000000            1   \n",
      "6       15.908748      1.144251         6.650841        0.237424            1   \n",
      "7       59.375525      0.492913        16.197749        0.779790            1   \n",
      "8       13.254249      1.874090         0.000000        0.000000            5   \n",
      "9       64.802014      5.039892         0.000000        0.000000            5   \n",
      "10      17.106166      0.331884        10.056681        0.265500            5   \n",
      "11      64.428468      0.057737        14.072207        1.542469            5   \n",
      "12      17.326075      1.729340         0.000000        0.000000           10   \n",
      "13      32.808288      5.216640         0.000000        0.000000           10   \n",
      "14      16.927096      0.939029         7.816340        0.681774           10   \n",
      "15      86.936404     34.552793        29.037588        6.614908           10   \n",
      "16      27.475067      7.738800         0.000000        0.000000           50   \n",
      "17     165.061451      7.692041         0.000000        0.000000           50   \n",
      "18      56.193638      8.723068        10.231540        0.046441           50   \n",
      "19      87.604262     13.357336        29.000221        6.296128           50   \n",
      "20      27.964908      1.177312         0.000000        0.000000          100   \n",
      "21      75.604273      4.077948         0.000000        0.000000          100   \n",
      "22      24.201808      2.564455        10.010161        5.881940          100   \n",
      "23      25.078216      0.317654         5.030887        0.445104          100   \n",
      "\n",
      "   param_clf__penalty param_vect__ngram_range  \\\n",
      "0                  l1                  (1, 2)   \n",
      "1                  l1                  (1, 3)   \n",
      "2                  l2                  (1, 2)   \n",
      "3                  l2                  (1, 3)   \n",
      "4                  l1                  (1, 2)   \n",
      "5                  l1                  (1, 3)   \n",
      "6                  l2                  (1, 2)   \n",
      "7                  l2                  (1, 3)   \n",
      "8                  l1                  (1, 2)   \n",
      "9                  l1                  (1, 3)   \n",
      "10                 l2                  (1, 2)   \n",
      "11                 l2                  (1, 3)   \n",
      "12                 l1                  (1, 2)   \n",
      "13                 l1                  (1, 3)   \n",
      "14                 l2                  (1, 2)   \n",
      "15                 l2                  (1, 3)   \n",
      "16                 l1                  (1, 2)   \n",
      "17                 l1                  (1, 3)   \n",
      "18                 l2                  (1, 2)   \n",
      "19                 l2                  (1, 3)   \n",
      "20                 l1                  (1, 2)   \n",
      "21                 l1                  (1, 3)   \n",
      "22                 l2                  (1, 2)   \n",
      "23                 l2                  (1, 3)   \n",
      "\n",
      "                                               params  split0_test_score  \\\n",
      "0   {'clf__C': 0.5, 'clf__penalty': 'l1', 'vect__n...                NaN   \n",
      "1   {'clf__C': 0.5, 'clf__penalty': 'l1', 'vect__n...                NaN   \n",
      "2   {'clf__C': 0.5, 'clf__penalty': 'l2', 'vect__n...           0.931910   \n",
      "3   {'clf__C': 0.5, 'clf__penalty': 'l2', 'vect__n...           0.931709   \n",
      "4   {'clf__C': 1, 'clf__penalty': 'l1', 'vect__ngr...                NaN   \n",
      "5   {'clf__C': 1, 'clf__penalty': 'l1', 'vect__ngr...                NaN   \n",
      "6   {'clf__C': 1, 'clf__penalty': 'l2', 'vect__ngr...           0.937088   \n",
      "7   {'clf__C': 1, 'clf__penalty': 'l2', 'vect__ngr...           0.936973   \n",
      "8   {'clf__C': 5, 'clf__penalty': 'l1', 'vect__ngr...                NaN   \n",
      "9   {'clf__C': 5, 'clf__penalty': 'l1', 'vect__ngr...                NaN   \n",
      "10  {'clf__C': 5, 'clf__penalty': 'l2', 'vect__ngr...           0.940627   \n",
      "11  {'clf__C': 5, 'clf__penalty': 'l2', 'vect__ngr...           0.939562   \n",
      "12  {'clf__C': 10, 'clf__penalty': 'l1', 'vect__ng...                NaN   \n",
      "13  {'clf__C': 10, 'clf__penalty': 'l1', 'vect__ng...                NaN   \n",
      "14  {'clf__C': 10, 'clf__penalty': 'l2', 'vect__ng...           0.939275   \n",
      "15  {'clf__C': 10, 'clf__penalty': 'l2', 'vect__ng...           0.938066   \n",
      "16  {'clf__C': 50, 'clf__penalty': 'l1', 'vect__ng...                NaN   \n",
      "17  {'clf__C': 50, 'clf__penalty': 'l1', 'vect__ng...                NaN   \n",
      "18  {'clf__C': 50, 'clf__penalty': 'l2', 'vect__ng...           0.931191   \n",
      "19  {'clf__C': 50, 'clf__penalty': 'l2', 'vect__ng...           0.928228   \n",
      "20  {'clf__C': 100, 'clf__penalty': 'l1', 'vect__n...                NaN   \n",
      "21  {'clf__C': 100, 'clf__penalty': 'l1', 'vect__n...                NaN   \n",
      "22  {'clf__C': 100, 'clf__penalty': 'l2', 'vect__n...           0.927020   \n",
      "23  {'clf__C': 100, 'clf__penalty': 'l2', 'vect__n...           0.923050   \n",
      "\n",
      "    split1_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "0                 NaN              NaN             NaN               24  \n",
      "1                 NaN              NaN             NaN               20  \n",
      "2            0.931508         0.931709        0.000201                8  \n",
      "3            0.931565         0.931637        0.000072                9  \n",
      "4                 NaN              NaN             NaN               19  \n",
      "5                 NaN              NaN             NaN               16  \n",
      "6            0.936628         0.936858        0.000230                5  \n",
      "7            0.936053         0.936513        0.000460                6  \n",
      "8                 NaN              NaN             NaN               15  \n",
      "9                 NaN              NaN             NaN               23  \n",
      "10           0.941202         0.940914        0.000288                1  \n",
      "11           0.940655         0.940109        0.000547                3  \n",
      "12                NaN              NaN             NaN               13  \n",
      "13                NaN              NaN             NaN               14  \n",
      "14           0.941317         0.940296        0.001021                2  \n",
      "15           0.940885         0.939476        0.001410                4  \n",
      "16                NaN              NaN             NaN               17  \n",
      "17                NaN              NaN             NaN               18  \n",
      "18           0.936599         0.933895        0.002704                7  \n",
      "19           0.934327         0.931278        0.003049               10  \n",
      "20                NaN              NaN             NaN               21  \n",
      "21                NaN              NaN             NaN               22  \n",
      "22           0.932025         0.929523        0.002503               11  \n",
      "23           0.931105         0.927078        0.004027               12  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(clf.cv_results_)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   param_vect__ngram_range param_clf__penalty param_clf__C  \\\n",
      "0                   (1, 2)                 l1          0.5   \n",
      "1                   (1, 3)                 l1          0.5   \n",
      "2                   (1, 2)                 l2          0.5   \n",
      "3                   (1, 3)                 l2          0.5   \n",
      "4                   (1, 2)                 l1            1   \n",
      "5                   (1, 3)                 l1            1   \n",
      "6                   (1, 2)                 l2            1   \n",
      "7                   (1, 3)                 l2            1   \n",
      "8                   (1, 2)                 l1            5   \n",
      "9                   (1, 3)                 l1            5   \n",
      "10                  (1, 2)                 l2            5   \n",
      "11                  (1, 3)                 l2            5   \n",
      "12                  (1, 2)                 l1           10   \n",
      "13                  (1, 3)                 l1           10   \n",
      "14                  (1, 2)                 l2           10   \n",
      "15                  (1, 3)                 l2           10   \n",
      "16                  (1, 2)                 l1           50   \n",
      "17                  (1, 3)                 l1           50   \n",
      "18                  (1, 2)                 l2           50   \n",
      "19                  (1, 3)                 l2           50   \n",
      "20                  (1, 2)                 l1          100   \n",
      "21                  (1, 3)                 l1          100   \n",
      "22                  (1, 2)                 l2          100   \n",
      "23                  (1, 3)                 l2          100   \n",
      "\n",
      "   param_vect__ngram_range  mean_test_score  rank_test_score  \n",
      "0                   (1, 2)              NaN               24  \n",
      "1                   (1, 3)              NaN               20  \n",
      "2                   (1, 2)         0.931709                8  \n",
      "3                   (1, 3)         0.931637                9  \n",
      "4                   (1, 2)              NaN               19  \n",
      "5                   (1, 3)              NaN               16  \n",
      "6                   (1, 2)         0.936858                5  \n",
      "7                   (1, 3)         0.936513                6  \n",
      "8                   (1, 2)              NaN               15  \n",
      "9                   (1, 3)              NaN               23  \n",
      "10                  (1, 2)         0.940914                1  \n",
      "11                  (1, 3)         0.940109                3  \n",
      "12                  (1, 2)              NaN               13  \n",
      "13                  (1, 3)              NaN               14  \n",
      "14                  (1, 2)         0.940296                2  \n",
      "15                  (1, 3)         0.939476                4  \n",
      "16                  (1, 2)              NaN               17  \n",
      "17                  (1, 3)              NaN               18  \n",
      "18                  (1, 2)         0.933895                7  \n",
      "19                  (1, 3)         0.931278               10  \n",
      "20                  (1, 2)              NaN               21  \n",
      "21                  (1, 3)              NaN               22  \n",
      "22                  (1, 2)         0.929523               11  \n",
      "23                  (1, 3)         0.927078               12  \n"
     ]
    }
   ],
   "source": [
    "print(df[['param_vect__ngram_range','param_clf__penalty','param_clf__C', 'param_vect__ngram_range','mean_test_score', 'rank_test_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 2/24] START clf__C=0.5, clf__penalty=l1, vect__ngram_range=(1, 3)......\n",
      "[CV 2/2; 2/24] END clf__C=0.5, clf__penalty=l1, vect__ngram_range=(1, 3);, score=nan total time=  42.3s\n",
      "[CV 2/2; 8/24] START clf__C=1, clf__penalty=l2, vect__ngram_range=(1, 3)........\n",
      "[CV 2/2; 8/24] END clf__C=1, clf__penalty=l2, vect__ngram_range=(1, 3);, score=0.936 total time=  56.1s\n",
      "[CV 1/2; 16/24] START clf__C=10, clf__penalty=l2, vect__ngram_range=(1, 3)......\n",
      "[CV 1/2; 16/24] END clf__C=10, clf__penalty=l2, vect__ngram_range=(1, 3);, score=0.938 total time= 1.4min\n",
      "[CV 1/2; 23/24] START clf__C=100, clf__penalty=l2, vect__ngram_range=(1, 2).....\n",
      "[CV 1/2; 23/24] END clf__C=100, clf__penalty=l2, vect__ngram_range=(1, 2);, score=0.927 total time=  27.9s\n",
      "[CV 2/2; 1/24] START clf__C=0.5, clf__penalty=l1, vect__ngram_range=(1, 2)......\n",
      "[CV 2/2; 1/24] END clf__C=0.5, clf__penalty=l1, vect__ngram_range=(1, 2);, score=nan total time=  11.9s\n",
      "[CV 2/2; 5/24] START clf__C=1, clf__penalty=l1, vect__ngram_range=(1, 2)........\n",
      "[CV 2/2; 5/24] END clf__C=1, clf__penalty=l1, vect__ngram_range=(1, 2);, score=nan total time=  14.1s\n",
      "[CV 2/2; 7/24] START clf__C=1, clf__penalty=l2, vect__ngram_range=(1, 2)........\n",
      "[CV 2/2; 7/24] END clf__C=1, clf__penalty=l2, vect__ngram_range=(1, 2);, score=0.937 total time=  19.4s\n",
      "[CV 2/2; 9/24] START clf__C=5, clf__penalty=l1, vect__ngram_range=(1, 2)........\n",
      "[CV 2/2; 9/24] END clf__C=5, clf__penalty=l1, vect__ngram_range=(1, 2);, score=nan total time=  12.1s\n",
      "[CV 2/2; 12/24] START clf__C=5, clf__penalty=l2, vect__ngram_range=(1, 3).......\n",
      "[CV 2/2; 12/24] END clf__C=5, clf__penalty=l2, vect__ngram_range=(1, 3);, score=0.941 total time= 1.0min\n",
      "[CV 2/2; 17/24] START clf__C=50, clf__penalty=l1, vect__ngram_range=(1, 2)......\n",
      "[CV 2/2; 17/24] END clf__C=50, clf__penalty=l1, vect__ngram_range=(1, 2);, score=nan total time=  26.8s\n",
      "[CV 2/2; 19/24] START clf__C=50, clf__penalty=l2, vect__ngram_range=(1, 2)......\n",
      "[CV 2/2; 19/24] END clf__C=50, clf__penalty=l2, vect__ngram_range=(1, 2);, score=0.937 total time=  24.6s\n",
      "[CV 1/2; 22/24] START clf__C=100, clf__penalty=l1, vect__ngram_range=(1, 3).....\n",
      "[CV 1/2; 22/24] END clf__C=100, clf__penalty=l1, vect__ngram_range=(1, 3);, score=nan total time=  33.2s\n",
      "[CV 1/2; 3/24] START clf__C=0.5, clf__penalty=l2, vect__ngram_range=(1, 2)......\n",
      "[CV 1/2; 3/24] END clf__C=0.5, clf__penalty=l2, vect__ngram_range=(1, 2);, score=0.932 total time=  19.7s\n",
      "[CV 1/2; 6/24] START clf__C=1, clf__penalty=l1, vect__ngram_range=(1, 3)........\n",
      "[CV 1/2; 6/24] END clf__C=1, clf__penalty=l1, vect__ngram_range=(1, 3);, score=nan total time=  34.7s\n",
      "[CV 1/2; 11/24] START clf__C=5, clf__penalty=l2, vect__ngram_range=(1, 2).......\n",
      "[CV 1/2; 11/24] END clf__C=5, clf__penalty=l2, vect__ngram_range=(1, 2);, score=0.941 total time=  28.2s\n",
      "[CV 1/2; 13/24] START clf__C=10, clf__penalty=l1, vect__ngram_range=(1, 2)......\n",
      "[CV 1/2; 13/24] END clf__C=10, clf__penalty=l1, vect__ngram_range=(1, 2);, score=nan total time=  14.6s\n",
      "[CV 1/2; 15/24] START clf__C=10, clf__penalty=l2, vect__ngram_range=(1, 2)......\n",
      "[CV 1/2; 15/24] END clf__C=10, clf__penalty=l2, vect__ngram_range=(1, 2);, score=0.939 total time=  26.7s\n",
      "[CV 1/2; 18/24] START clf__C=50, clf__penalty=l1, vect__ngram_range=(1, 3)......\n",
      "[CV 1/2; 18/24] END clf__C=50, clf__penalty=l1, vect__ngram_range=(1, 3);, score=nan total time=  42.2s\n",
      "[CV 2/2; 21/24] START clf__C=100, clf__penalty=l1, vect__ngram_range=(1, 2).....\n",
      "[CV 2/2; 21/24] END clf__C=100, clf__penalty=l1, vect__ngram_range=(1, 2);, score=nan total time=  15.4s\n",
      "[CV 2/2; 23/24] START clf__C=100, clf__penalty=l2, vect__ngram_range=(1, 2).....\n",
      "[CV 2/2; 23/24] END clf__C=100, clf__penalty=l2, vect__ngram_range=(1, 2);, score=0.932 total time=  20.4s\n",
      "[CV 1/2; 1/24] START clf__C=0.5, clf__penalty=l1, vect__ngram_range=(1, 2)......\n",
      "[CV 1/2; 1/24] END clf__C=0.5, clf__penalty=l1, vect__ngram_range=(1, 2);, score=nan total time=  11.2s\n",
      "[CV 1/2; 5/24] START clf__C=1, clf__penalty=l1, vect__ngram_range=(1, 2)........\n",
      "[CV 1/2; 5/24] END clf__C=1, clf__penalty=l1, vect__ngram_range=(1, 2);, score=nan total time=  14.6s\n",
      "[CV 1/2; 7/24] START clf__C=1, clf__penalty=l2, vect__ngram_range=(1, 2)........\n",
      "[CV 1/2; 7/24] END clf__C=1, clf__penalty=l2, vect__ngram_range=(1, 2);, score=0.937 total time=  21.1s\n",
      "[CV 1/2; 9/24] START clf__C=5, clf__penalty=l1, vect__ngram_range=(1, 2)........\n",
      "[CV 1/2; 9/24] END clf__C=5, clf__penalty=l1, vect__ngram_range=(1, 2);, score=nan total time=  11.7s\n",
      "[CV 1/2; 12/24] START clf__C=5, clf__penalty=l2, vect__ngram_range=(1, 3).......\n",
      "[CV 1/2; 12/24] END clf__C=5, clf__penalty=l2, vect__ngram_range=(1, 3);, score=0.940 total time=  57.2s\n",
      "[CV 1/2; 17/24] START clf__C=50, clf__penalty=l1, vect__ngram_range=(1, 2)......\n",
      "[CV 1/2; 17/24] END clf__C=50, clf__penalty=l1, vect__ngram_range=(1, 2);, score=nan total time=  23.1s\n",
      "[CV 1/2; 19/24] START clf__C=50, clf__penalty=l2, vect__ngram_range=(1, 2)......\n",
      "[CV 1/2; 19/24] END clf__C=50, clf__penalty=l2, vect__ngram_range=(1, 2);, score=0.931 total time=  25.2s\n",
      "[CV 1/2; 21/24] START clf__C=100, clf__penalty=l1, vect__ngram_range=(1, 2).....\n",
      "[CV 1/2; 21/24] END clf__C=100, clf__penalty=l1, vect__ngram_range=(1, 2);, score=nan total time=  11.3s\n",
      "[CV 2/2; 22/24] START clf__C=100, clf__penalty=l1, vect__ngram_range=(1, 3).....\n",
      "[CV 2/2; 22/24] END clf__C=100, clf__penalty=l1, vect__ngram_range=(1, 3);, score=nan total time=  37.9s\n",
      "[CV 1/2; 2/24] START clf__C=0.5, clf__penalty=l1, vect__ngram_range=(1, 3)......\n",
      "[CV 1/2; 2/24] END clf__C=0.5, clf__penalty=l1, vect__ngram_range=(1, 3);, score=nan total time=  41.4s\n",
      "[CV 1/2; 8/24] START clf__C=1, clf__penalty=l2, vect__ngram_range=(1, 3)........\n",
      "[CV 1/2; 8/24] END clf__C=1, clf__penalty=l2, vect__ngram_range=(1, 3);, score=0.937 total time=  53.3s\n",
      "[CV 2/2; 14/24] START clf__C=10, clf__penalty=l1, vect__ngram_range=(1, 3)......\n",
      "[CV 2/2; 14/24] END clf__C=10, clf__penalty=l1, vect__ngram_range=(1, 3);, score=nan total time= 1.2min\n",
      "[CV 2/2; 20/24] START clf__C=50, clf__penalty=l2, vect__ngram_range=(1, 3)......\n",
      "[CV 2/2; 20/24] END clf__C=50, clf__penalty=l2, vect__ngram_range=(1, 3);, score=0.934 total time=  51.5s\n",
      "[CV 2/2; 4/24] START clf__C=0.5, clf__penalty=l2, vect__ngram_range=(1, 3)......\n",
      "[CV 2/2; 4/24] END clf__C=0.5, clf__penalty=l2, vect__ngram_range=(1, 3);, score=0.932 total time=  49.1s\n",
      "[CV 1/2; 10/24] START clf__C=5, clf__penalty=l1, vect__ngram_range=(1, 3).......\n",
      "[CV 1/2; 10/24] END clf__C=5, clf__penalty=l1, vect__ngram_range=(1, 3);, score=nan total time=  37.9s\n",
      "[CV 1/2; 14/24] START clf__C=10, clf__penalty=l1, vect__ngram_range=(1, 3)......\n",
      "[CV 1/2; 14/24] END clf__C=10, clf__penalty=l1, vect__ngram_range=(1, 3);, score=nan total time= 1.3min\n",
      "[CV 1/2; 20/24] START clf__C=50, clf__penalty=l2, vect__ngram_range=(1, 3)......\n",
      "[CV 1/2; 20/24] END clf__C=50, clf__penalty=l2, vect__ngram_range=(1, 3);, score=0.928 total time=  53.1s\n",
      "[CV 1/2; 4/24] START clf__C=0.5, clf__penalty=l2, vect__ngram_range=(1, 3)......\n",
      "[CV 1/2; 4/24] END clf__C=0.5, clf__penalty=l2, vect__ngram_range=(1, 3);, score=0.932 total time=  53.3s\n",
      "[CV 2/2; 10/24] START clf__C=5, clf__penalty=l1, vect__ngram_range=(1, 3).......\n",
      "[CV 2/2; 10/24] END clf__C=5, clf__penalty=l1, vect__ngram_range=(1, 3);, score=nan total time=  46.7s\n",
      "[CV 2/2; 15/24] START clf__C=10, clf__penalty=l2, vect__ngram_range=(1, 2)......\n",
      "[CV 2/2; 15/24] END clf__C=10, clf__penalty=l2, vect__ngram_range=(1, 2);, score=0.941 total time=  30.6s\n",
      "[CV 2/2; 18/24] START clf__C=50, clf__penalty=l1, vect__ngram_range=(1, 3)......\n",
      "[CV 2/2; 18/24] END clf__C=50, clf__penalty=l1, vect__ngram_range=(1, 3);, score=nan total time=  57.5s\n",
      "[CV 1/2; 24/24] START clf__C=100, clf__penalty=l2, vect__ngram_range=(1, 3).....\n",
      "[CV 1/2; 24/24] END clf__C=100, clf__penalty=l2, vect__ngram_range=(1, 3);, score=0.923 total time=  32.0s\n",
      "[CV 2/2; 3/24] START clf__C=0.5, clf__penalty=l2, vect__ngram_range=(1, 2)......\n",
      "[CV 2/2; 3/24] END clf__C=0.5, clf__penalty=l2, vect__ngram_range=(1, 2);, score=0.932 total time=  20.5s\n",
      "[CV 2/2; 6/24] START clf__C=1, clf__penalty=l1, vect__ngram_range=(1, 3)........\n",
      "[CV 2/2; 6/24] END clf__C=1, clf__penalty=l1, vect__ngram_range=(1, 3);, score=nan total time=  36.6s\n",
      "[CV 2/2; 11/24] START clf__C=5, clf__penalty=l2, vect__ngram_range=(1, 2).......\n",
      "[CV 2/2; 11/24] END clf__C=5, clf__penalty=l2, vect__ngram_range=(1, 2);, score=0.941 total time=  28.8s\n",
      "[CV 2/2; 13/24] START clf__C=10, clf__penalty=l1, vect__ngram_range=(1, 2)......\n",
      "[CV 2/2; 13/24] END clf__C=10, clf__penalty=l1, vect__ngram_range=(1, 2);, score=nan total time=  15.1s\n",
      "[CV 2/2; 16/24] START clf__C=10, clf__penalty=l2, vect__ngram_range=(1, 3)......\n",
      "[CV 2/2; 16/24] END clf__C=10, clf__penalty=l2, vect__ngram_range=(1, 3);, score=0.941 total time= 1.5min\n",
      "[CV 2/2; 24/24] START clf__C=100, clf__penalty=l2, vect__ngram_range=(1, 3).....\n",
      "[CV 2/2; 24/24] END clf__C=100, clf__penalty=l2, vect__ngram_range=(1, 3);, score=0.931 total time=  27.4s\n"
     ]
    }
   ],
   "source": [
    "print(“Best score: %0.3f” % clf._best_score_)\n",
    "print(clf._best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lessons Learnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g. What hyperparameter tuning did you do, and by how many percentage points did your accuracy go up because of hyper-parameter tuning?\n",
    "\n",
    "I give paramters for the n_gram, clf_penalty, clf_c, and vect_n_gram_range .\n",
    "And the best result is the n_gram: (1,2), clf_penalty: l2, clf_c: 5, vect_n_gram_range: (1,2) \n",
    "\n",
    "### h. What did you learn from the different metrics? How useful was it to use cross-validation?\n",
    "Different models have different paramterss. We use k-fold cross-validation and set k = 2. Therefore, we attempt to maximize the use of the available data for training and then testing a model\n",
    "\n",
    "### i. What are your best final Result Metrics? What is the increase in accuracy compared to thestrawman figure? Which model gave you this performance?\n",
    "LogisticRegression model gave me the best result.\n",
    "The accuracy improves from 0.91 to 0.94 after the hypermeter tuning\n",
    "\n",
    "### j. What is the most interesting thing you learned from doing the report?\n",
    "Oversampling will not necessarily improve the performance of the model\n",
    "\n",
    "### k. What was the hardest thing to do?\n",
    "Run the ML model over and over again, and compare the confusion table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prevalence of personal attacks by namespace\n",
    "In this section we use our classifier in conjunction with the [Wikipedia Talk Corpus](https://figshare.com/articles/Wikipedia_Talk_Corpus/4264973) to see if personal attacks are more common on user talk or article talk page discussions. In our paper we show that the model is not biased by namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from scipy.stats import bernoulli\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and untar data\n",
    "\n",
    "USER_TALK_CORPUS_2004_URL = 'https://ndownloader.figshare.com/files/6982061'\n",
    "ARTICLE_TALK_CORPUS_2004_URL = 'https://ndownloader.figshare.com/files/7038050'\n",
    "\n",
    "download_file(USER_TALK_CORPUS_2004_URL, 'comments_user_2004.tar.gz')\n",
    "download_file(ARTICLE_TALK_CORPUS_2004_URL,  'comments_article_2004.tar.gz')\n",
    "\n",
    "os.system('tar -xzf comments_user_2004.tar.gz')\n",
    "os.system('tar -xzf comments_article_2004.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper for collecting a sample of comments for a given ns and year from \n",
    "def load_no_bot_no_admin(ns, year, prob = 0.1):\n",
    "    \n",
    "    dfs = []\n",
    "    \n",
    "    data_dir = \"comments_%s_%d\" % (ns, year)\n",
    "    for _, _, filenames in os.walk(data_dir):\n",
    "        for filename in filenames:\n",
    "            if re.match(\"chunk_\\d*.tsv\", filename):\n",
    "                df = pd.read_csv(os.path.join(data_dir, filename), sep = \"\\t\")\n",
    "                df['include'] = bernoulli.rvs(prob, size=df.shape[0])\n",
    "                df = df.query(\"bot == 0 and admin == 0 and include == 1\")\n",
    "                dfs.append(df)\n",
    "                \n",
    "    sample = pd.concat(dfs)\n",
    "    sample['ns'] = ns\n",
    "    sample['year'] = year\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect a random sample of comments from 2004 for each namespace\n",
    "corpus_user = load_no_bot_no_admin('user', 2004)\n",
    "corpus_article = load_no_bot_no_admin('article', 2004)\n",
    "corpus = pd.concat([corpus_user, corpus_article])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply model\n",
    "corpus['comment'] = corpus['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "corpus['comment'] = corpus['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))\n",
    "corpus['attack'] = clf.predict_proba(corpus['comment'])[:,1] > 0.425 # see paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot prevalence per ns\n",
    "\n",
    "sns.pointplot(data = corpus, x = 'ns', y = 'attack')\n",
    "plt.ylabel(\"Attack fraction\")\n",
    "plt.xlabel(\"Dicussion namespace\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attacks are far more prevalent in the user talk namespace."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
